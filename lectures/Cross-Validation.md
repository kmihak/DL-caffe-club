"*Model selection strategies for machine learning algorithms typically involve the numerical optimisation of an appropriate model selection criterion, often based on an estimator of generalisation performance, such as k-fold cross-validation. The error of such an estimator can be broken down into bias and variance components. While unbiasedness is often cited as a beneficial quality of a model selection criterion, we demonstrate that a low variance is at least as important, as a non-negligible variance introduces the potential for over-fitting in model selection as well as in training the model. While this observation is in hindsight perhaps rather obvious, the degradation in performance due to over-fitting the model selection criterion can be surprisingly large, an observation that appears to have received little attention in the machine learning literature to date.*" Gavin C. Cawley, Nicola L. C. Talbot; 11(70):2079âˆ’2107, 2010 Nested-CV[paper](https://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf)

BBC-CV [github](https://github.com/mensxmachina/BBC-CV) [paper](https://link.springer.com/article/10.1007/s10994-018-5714-4)